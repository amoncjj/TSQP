Describe the benefits of running large language model inference inside a TEE.
Summarize the security challenges of heterogeneous inference pipelines.
Provide five potential attack vectors against GPU-assisted inference and their mitigations.
